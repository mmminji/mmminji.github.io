---
layout: post
title:  "선형대수와 통계학으로 배우는 머신러닝 with 파이썬 7장"
date:   2021-05-11
categories: MachineLearning 
---
[Book Review] 한줄정리

# 7 모형 평가

## 7.1 오버피팅과 언더피팅
오버피팅이란, 특정 데이터 셋에 과도하게 적합된 것을 말한다. 이는 테스트 데이터에 대해서 예측력이 낮아진다.  
반대로 언더피팅이란, 데이터 셋에 적합이 잘되지 않고 과소 적합된 것을 말한다.  
편향-분산 트레이드오프(bias-variance tradeoff)는 편향이 높으면 분산이 작아지는(편향이 낮으면 분산이 높아지는) 서로 반대의 경향을 보이는 것이다.  
예) 복잡한 모형 --> 오버피팅 발생 가능성 높음 --> 분산이 커짐  
    간단한 모형 --> 언더피팅 발생 가능성 높음 --> 편향이 커짐

## 7.2 크로스-밸리데이션
Cross Validation(교차검증)이란, 오버피팅과 언더피팅을 방지하기 위한 방법 중 하나이다. 이는 데이터를 분할할 수 있는 다양한 조합을 통해서 모형의 성능을 검증하는 방법이다. 만약 k개로 분할하여 조합을 바꾼다면 K-fold cross-validation이라고 부른다.  
![4-fold cross-validation](https://github.com/mmminji/mmminji.github.io/blob/main/assets/post_pics/7.2-CV.png?raw=true){: width="700" height="300"}

- 다양한 머신러닝 알고리즘 적용시
    - 파라미터 : 모형 내부에서 데이터에 의해 추정되는 값
    - 하이퍼파라미터 : 데이터로부터 나온 값이 아닌, 사용자가 직접 정하는 값
- 데이터 분할
    - Train 데이터 : 데이터 학습 시 사용, 파라미터 구하는데 사용
    - Validation 데이터 : 하이퍼파라미터를 정하는데 사용
    - Test 데이터 : 모형의 성능을 평가하는데 사용

## 7.3 파이프라인 [>코드<](https://github.com/mmminji/Machine-Learning/blob/master/4.Pipeline.py)
파이프라인을 사용하면 데이터 전처리와 학습 모형을 연결해 간단하게 코드를 작성할 수 있다.

## 7.4 그리드 서치 [>코드<](https://github.com/mmminji/Machine-Learning/blob/master/5.GridSearchCV.py)
Grid Search란, 여러 매개 변수들을 대상으로 모델의 성능을 비교하여 최적의 하이퍼파라미터를 선정하는 과정을 말한다.

## 7.5 손실 함수와 비용 함수

### 7.5.1 손실 함수와 비용 함수의 개념
Loss function(손실 함수)은 실젯값과 예측값의 차이로 모형의 손실을 나타내는 함수이다. 손실 함수는 각 데이터 포인트에 대해서 차이를 나타내고, 비용 함수는 데이터 셋 전체를 대상으로 손실을 나타낸다.

### 7.5.2 L1 손실 함수
L1 손실은 실젯값과 예측값의 차이에 기댓값을 취한 것으로, 관련된 비용 함수는 MAE(Mean Absolute Error)이다.  

$L1 loss = \sum \left | y_{true}-y_{predict} \right |$  
$MAE = \frac{1}{n}\sum_{i=1}^{n}\left | y_{i}-\hat{y_{i}} \right |$  

### 7.5.3 L2 손실 함수
L2 손실은 실젯값과 예측값의 차이에 제곱을 취한 것으로, 관련된 비용 함수에는 MSE(Mean Squared Error), RMSE(Root Mean Squared Error)가 있다.


이 내용은 **선형대수와 통계학으로 배우는 머신러닝 with 파이썬 : 최적화 개념부터 텐서플로를 활용한 딥러닝까지** 책을 기반으로 공부한 자료입니다.
